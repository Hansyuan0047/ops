apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-spring-myapp
  namespace: ateng-spark
spec:
  type: Java
  mode: cluster
  image: "registry.lingo.local/service/spark:3.5.4"
  imagePullPolicy: Always
  proxyUser: admin
  #mainClass: org.apache.spark.examples.SparkPi
  arguments:
    - "--class=local.ateng.java.spark.sql.SQLCount"
    - "--method=run"
  mainApplicationFile: "http://192.168.1.12:9000/test/spark/spark-cluster-v1.0.jar"
  sparkVersion: "3.5.4"
  sparkUIOptions:
    serviceType: NodePort
  dynamicAllocation:
    enabled: true
    initialExecutors: 1
    maxExecutors: 5
    minExecutors: 1
  restartPolicy:
    type: Never
  driver:
    cores: 2
    coreLimit: "2"
    coreRequest: "1"
    memory: "2g"
    env:
      - name: TZ
        value: Asia/Shanghai      
    labels:
      version: 3.5.4
      app.kubernetes.io/name: spark-spring-myapp
      app.kubernetes.io/component: driver
    hostAliases:
      - ip: "192.168.1.18"
        hostnames:
          - "server01"
    serviceAccount: spark-operator-spark
  executor:
    cores: 2
    coreLimit: "2"
    coreRequest: "1"
    memory: "4g"
    instances: 1
    env:
      - name: TZ
        value: Asia/Shanghai      
    labels:
      version: 3.5.4
      app.kubernetes.io/name: spark-spring-myapp
      app.kubernetes.io/component: executor
    hostAliases:
      - ip: "192.168.1.18"
        hostnames:
          - "server01"
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: spark-spring-myapp
                  app.kubernetes.io/component: executor
              topologyKey: kubernetes.io/hostname
            weight: 1
